package filodb.core.memstore

import kamon.Kamon
import monix.eval.Task
import monix.reactive.Observable

import filodb.core.DatasetRef
import filodb.core.store.{ColumnStore, PartKeyRecord}

class IndexBootstrapper(colStore: ColumnStore) {

  /**
    * Bootstrap the lucene index for the shard
    * using PartKeyRecord objects read from some persistent source.
    *
    * The partId used in the lucene index is generated by invoking
    * the function provided on the threadpool requested.
    *
    * @param index the lucene index to populate
    * @param shardNum shard number
    * @param ref dataset ref
    * @param assignPartId the function to invoke to get the partitionId to be used to populate the index record
    * @return number of updated records
    */
  def bootstrapIndex(index: PartKeyLuceneIndex,
                     shardNum: Int,
                     ref: DatasetRef)
                     (assignPartId: PartKeyRecord => Int): Task[Long] = {
    val tracer = Kamon.spanBuilder("memstore-recover-index-latency")
      .asChildOf(Kamon.currentSpan())
      .tag("dataset", ref.dataset)
      .tag("shard", shardNum).start()

    colStore.scanPartKeys(ref, shardNum)
      .map { pk =>
        val partId = assignPartId(pk)
        index.addPartKey(pk.partKey, partId, pk.startTime, pk.endTime)()
      }
      .countL
      .map { count =>
        index.refreshReadersBlocking()
        tracer.finish()
        count
      }
  }

  /**
    * Refresh index
    * @param fromHour
    * @param toHour
    * @param parallelism
    * @param lookUpOrAssignPartId
    * @return
    */
  def refreshIndex(index: PartKeyLuceneIndex,
                   shardNum: Int,
                   ref: DatasetRef,
                   fromHour: Long,
                   toHour: Long,
                   parallelism: Int = Runtime.getRuntime.availableProcessors())
                  (lookUpOrAssignPartId: PartKeyRecord => Int): Task[Long] = {
    val tracer = Kamon.spanBuilder("downsample-store-refresh-index-latency")
      .asChildOf(Kamon.currentSpan())
      .tag("dataset", ref.dataset)
      .tag("shard", shardNum).start()

    Observable.fromIterable(fromHour to toHour).flatMap { hour =>
      colStore.getPartKeysByUpdateHour(ref, shardNum, hour)
    }.mapAsync(parallelism) { pk =>
      Task {
        val partId = lookUpOrAssignPartId(pk)
        index.upsertPartKey(pk.partKey, partId, pk.startTime, pk.endTime)()
      }
     }
     .countL
     .map { count =>
       index.refreshReadersBlocking()
       tracer.finish()

       count
     }
  }

}

