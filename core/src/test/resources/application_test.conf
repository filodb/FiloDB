{
  filodb {
    cassandra {
      hosts = ["localhost"]
      port = 9042
      keyspace = "unittest"
      admin-keyspace = "unittest"
      keyspace-replication-options = "{'class': 'SimpleStrategy', 'replication_factor': '1'}"
    }

    columnstore {
      # Number of cache entries for the table cache
      tablecache-size = 50

      # Number of ChunkRowMap entries to cache
      segment-cache-size = 1000

      # Maximum number of chunks to flush at one time using one Unlogged Batch.
      chunk-batch-size = 16

      # Maximum number of partitions that can be fetched at once that will still fit in
      # one Spark partition/thread when using IN clause in query.
      # If number of partitions are more than this limit then full table scan is performed.
      inquery-partitions-limit = 12
    }

    memtable {
      # Uncomment to enable mmap-file based memtable for persistence and easy recovery upon crashes.
      # Defaults to in-memory DB only which is lost upon restarts/crashes, but easier for testing.
      # local-filename = "/tmp/filodb.memtable"

      # Maximum rows per dataset/version before ingestRows throws back a PleaseWait.
      max-rows-per-table = 2000

      # Number of rows in memtable before flushes start being triggered
      flush-trigger-rows = 5000

      # Set the free memory requirement much lower for running tests
      min-free-mb = 10

      filo.chunksize = 100

      # Make this high enough that tests will require manual flushing usually
      write.interval = 5 s

      # This is to start flush on memtable when there is no write activity
      noactivity.flush.interval = 10 s
    }

    reprojector {
      # Number of times to retry a segment write.  Exponential backoff included.
      retries = 2
      retry-base-timeunit = 1 s

      segment-batch-size = 8
    }

    # Thread pool size for filodb.core reprojection and I/O tasks.
    core-futures-pool-size = 8
    core-futures-max-pool-size = 8

    # Thread pool queue length.  When queue is full, tasks get run in calling thread.
    core-futures-queue-length = 64
  }

  akka {
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    loglevel = "DEBUG"
    actor {
      debug {
        receive = on
        autoreceive = on
        # lifecycle = on
      }
    }
  }
}
